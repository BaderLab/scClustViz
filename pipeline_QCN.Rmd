---
title: "QCN"
output:
  md_document:
    toc: yes
---
# Quality control and normalization

```{r Setup, include=F}
input_dataPath <- "../meCortex/171116_Michael/" # path to 10X output directory (containing .mtx file)
dataPath <- "../scClustViz_files/" # path to analysis output directory
dataSpecies <- "mouse" #set species
dataName <- "testData" # name your data


library(Matrix)
library(scales)
library(viridis)
library(scran) # from Bioconductor


if (Sys.info()["sysname"] == "Windows") { sys <- "D:/" } else { sys <- "~/" }
if (dataSpecies == "mouse") {
  library(org.Mm.eg.db) # from Bioconductor
  egDB <- "org.Mm.eg.db"
  speciesMito <- "^mt-"
  #cycloneSpeciesMarkers <- "mouse_cycle_markers.rds" # Going to use Seurat's cell cycle annotations instead.
} else if (dataSpecies == "human") {
  library(org.Hs.eg.db) # from Bioconductor
  egDB <- "org.Hs.eg.db"
  speciesMito <- "^MT-"
  #cycloneSpeciesMarkers <- "human_cycle_markers.rds"
} else { print("Set species please!") }
dir.create(dataPath,recursive=T,showWarnings=F)

plotHistHoriz <- function(input,col="grey80",add=F) {
  tempH <- hist(input,breaks=50,plot=F)
  if (!add) {
    plot(x=NULL,y=NULL,xlim=range(tempH$counts),ylim=range(input),
         bty="n",ylab=NA,yaxt="n",xaxt="n",xlab=NA)
  }
  rect(xleft=rep(0,length(tempH$counts)),ybottom=tempH$breaks[-length(tempH$breaks)],
       xright=tempH$counts,ytop=tempH$breaks[-1],col=col)
}

rainbow2 <- function(n,a=1) {
  require(scales)
  hues = seq(15, 375, length = n + 1)
  alpha(hcl(h = hues, l = 60, c = 100)[1:n],a)
}
```

# Cell filtering

```{r load_data, include=F}
ebRaw <- counts(scater::read10xResults(input_dataPath))
ebRaw <- ebRaw[Matrix::rowSums(ebRaw) > 0,]
ebRaw <- ebRaw[,Matrix::colSums(ebRaw) > 0]

# Check rownames at this point.  This workflow expects MGI or HGNC gene symbols as the rownames.
# If the data was aligned to a reference genome that used ensembl gene IDs or another annotation
# you will have to either convert them to gene symbols, or identify which ensembl IDs correspond
# to the mitochondrial genome for the mitoFilt step.


# Consolidate duplicated gene names (a couple genes are in under their MGI and HGNC symbols)
if (any(duplicated(toupper(rownames(ebRaw))))) {
  print(paste(dataName,"-",sum(duplicated(toupper(rownames(ebRaw)))),"duplicated gene names."))
  temp_r <- which(as.logical(Matrix::rowSums(
    sapply(rownames(ebRaw)[duplicated(toupper(rownames(ebRaw)))],
           function(X) grepl(paste0("^",X,"$"),rownames(ebRaw),ignore.case=T)))))
  temp_r2 <- rownames(ebRaw[temp_r,])[rownames(ebRaw[temp_r,]) %in% keys(org.Mm.eg.db,"SYMBOL")]
  temp_reps <- t(sapply(lapply(unique(temp_r2),function(X) 
    grep(paste0("^",X,"$"),rownames(ebRaw),ignore.case=T)),
    function(Y) colSums(ebRaw[Y,])))
  rownames(temp_reps) <- temp_r2
  ebRaw <- ebRaw[-temp_r,]
  ebRaw <- rbind(ebRaw,temp_reps)
  ebRaw <- ebRaw[Matrix::rowSums(ebRaw) > 0,]
  ebRaw <- ebRaw[,Matrix::colSums(ebRaw) > 0]
}
rm(list=ls()[grepl("temp",ls())])
```

```{r plot_knee2, echo=F,fig.height=4.2,fig.width=8.4}
libSize <- Matrix::colSums(ebRaw)
cumCounts <- cumsum(libSize[order(libSize,decreasing=T)])
maxCount <- 10^ceiling(log10(max(libSize)))
countCols <- cut(log10(libSize[order(libSize,decreasing=T)]),
                 breaks=floor(log10(min(libSize))):ceiling(log10(max(libSize))),
                 labels=F,include.lowest=T)
layout(matrix(c(3,3,1:2),nrow=2,byrow=T),heights=c(1,3.2))
par(mar=c(3,3,1,1),mgp=2:0)
plot(seq_along(cumCounts),cumCounts/max(cumCounts),pch=19,ylim=c(0,1),
     col=viridis(max(countCols),d=-1)[countCols],
     xlab="Cell libraries (largest to smallest)",ylab="Cumulative fraction of UMIs")
plot(seq_along(cumCounts),cumCounts/max(cumCounts),pch=19,log="x",ylim=c(0,1),
     col=viridis(max(countCols),d=-1)[countCols],
     xlab="Cell libraries (largest to smallest)",ylab="Cumulative fraction of UMIs")
par(mar=c(3,1,2,1))
barplot(rep(1,max(countCols)),col=viridis(max(countCols),d=-1),
        space=0,border=NA,axes=F,xlab="UMIs per cell")
axis(side=1,at=0:max(countCols),
     labels=sapply(floor(log10(min(libSize))):ceiling(log10(max(libSize))),function(X) 10^X))
title(main="STAMPs from cells by UMIs per STAMP")
```

## Mitochondrial gene content  

Filtering cells based on the proportion of mitochondrial gene transcripts per cell.  A high proportion of mitochondrial gene transcripts are indicative of poor quality cells, probably due to compromised cell membranes.  Removal of these cells shouldn't decrease the complexity of the overall dataName (measured by number of genes detected), while removing a source of noise.  

```{r mitoFilt, echo=F,fig.height=4.2,fig.width=8.4}
### Parameters you could edit ###
drop_mitoMads <- 4 
# ^ Median absolute deviations from the median to use as threshold for mitochondrial transcript proprotion
hard_mitoCut <- 0.4 
# ^ Hard threshold for mitochondrial transcript proportion

### Calculations and filtering ###
temp_geneDetectFx <- function(ebRaw) { 
  if (is.null(slotNames(ebRaw))) {
    apply(ebRaw,2,function(X) sum(X>0))
  } else if ("j" %in% slotNames(ebRaw)) {
    as.vector(table(ebRaw@j))
  } else {
    as.vector(table(rep(seq_along(diff(ebRaw@p)),diff(ebRaw@p))))
  }
}
cellStats <- data.frame(libSize=Matrix::colSums(ebRaw),
                        geneDetect=temp_geneDetectFx(ebRaw),
                        mitoPct=Matrix::colSums(ebRaw[grepl(speciesMito,rownames(ebRaw)),]) / 
                          Matrix::colSums(ebRaw))

drop_mitoCut <- median(cellStats$mitoPct) + mad(cellStats$mitoPct) * drop_mitoMads
if (drop_mitoCut > hard_mitoCut) { drop_mitoCut <- hard_mitoCut }
drop_mito <- cellStats$mitoPct > drop_mitoCut

ebRawF <- ebRaw[,!drop_mito]
ebRawF <- ebRawF[Matrix::rowSums(ebRawF) > 0,]
cellStatsF <- cellStats[!drop_mito,]

### Plotting ###
layout(matrix(c(2,1,0,3,5,4,0,6),2),c(3.7,.5,3.7,.5),c(0.5,3.7))
par(mar=c(3,3,0,0),mgp=2:0)
plot(mitoPct~libSize,data=cellStats,log="x",
     pch=21,cex=1.2,col=alpha("black",0.2),bg=alpha("black",0.1),
     xlab="Transcripts detected per cell (log scale)",
     ylab="Transcript proportion from mitochondrial genome")
abline(h=drop_mitoCut,lwd=2,lty=2,col=alpha("red",0.5))
mtext(paste(dataName,"damaged cells"),side=3,adj=0.98,line=-1.5,font=2,cex=1)
legend("topright",bty="n",inset=c(0,.05),
       lty=c(2,NA,NA,NA,NA),lwd=c(2,NA,NA,NA,NA),col=alpha(c("red",NA,NA,NA,NA),0.5),
       legend=c(paste(drop_mitoMads,"MADs above median"),
                paste(sum(drop_mito),"cells removed"),
                paste(ncol(ebRawF),"cells remain"),
                paste(nrow(ebRaw)-nrow(ebRawF),"genes removed"),
                paste(nrow(ebRawF),"genes remain")))
par(mar=c(0,3,0,0))
hist(log10(cellStats$libSize),freq=F,breaks=50,col="grey80",
     main=NULL,xlab=NA,ylab=NA,xaxt="n",yaxt="n")
par(mar=c(3,0,0,0))
plotHistHoriz(cellStats$mitoPct)

par(mar=c(3,3,0,0))
plot(mitoPct~geneDetect,data=cellStats,log="x",
     pch=21,cex=1.2,col=alpha("black",0.2),bg=alpha("black",0.1),
     xlab="Genes detected per cell (log scale)",
     ylab="Transcript proportion from mitochondrial genome")
abline(h=drop_mitoCut,lwd=2,lty=2,col=alpha("red",0.5))
mtext(paste(dataName,"damaged cells"),side=3,adj=0.98,line=-1.5,font=2,cex=1)
legend("topright",bty="n",inset=c(0,.05),
       lty=c(2,NA,NA,NA,NA),lwd=c(2,NA,NA,NA,NA),col=alpha(c("red",NA,NA,NA,NA),0.5),
       legend=c(paste(drop_mitoMads,"MADs above median"),
                paste(sum(drop_mito),"cells removed"),
                paste(ncol(ebRawF),"cells remain"),
                paste(nrow(ebRaw)-nrow(ebRawF),"genes removed"),
                paste(nrow(ebRawF),"genes remain")))
par(mar=c(0,3,0,0))
hist(log10(cellStats$geneDetect),freq=F,breaks=50,col="grey80",
     main=NULL,xlab=NA,ylab=NA,xaxt="n",yaxt="n")
par(mar=c(3,0,0,0))
plotHistHoriz(cellStats$mitoPct)
```

## Outlier filtering  

While it isn't possible to explicitly filter for doublets at this stage (see [doublet filtering assessment](doubletFilterTest)), it is important to manually inspect the relationship between library size and gene detection rates per cell to identify obvious outliers.  Outliers can be identified systematically using a sufficiently extreme number of median absolute deviations from the median, assuming a moderately normal distribution.  Since library sizes tend to be log-normal, we use log-transformed library size to identify outliers.  We used 4 MADs above the median of the log-transformed library size as a threshold to define outliers.

```{r doubFilt, echo=F,fig.height=4.2,fig.width=8.4,fig.show="hold"}
### Parameters you could edit ###
outToInspect <- rep(F,nrow(cellStatsF)) # None
# outToRemove <- rep(F,nrow(cellStatsF)) # None
numMADs <- 3 # Median absolute deviations from the median to consider as an outlier.
outToRemove <- log10(cellStatsF$libSize) > median(log10(cellStatsF$libSize)) + 
  mad(log10(cellStats$libSize)) * numMADs
# Assuming an approximately log-normal distribution of library sizes, this removes obvious outliers. 
# (>3 MADs from the median of the log-transformed library size)

### Calculations and filtering ###
ebRawF2 <- ebRawF[,!outToRemove]
ebRawF2 <- ebRawF2[Matrix::rowSums(ebRawF2) > 0,]

### Plotting ###
layout(cbind(matrix(c(2,1,0,3),2),matrix(c(5,4,0,6),2)),widths=c(3.5,.7,3.5,.7),heights=c(.7,3.5))
par(mar=c(3,3,0,0),mgp=2:0)
plot(geneDetect~libSize,data=cellStatsF[!outToInspect,],
     xlim=range(cellStatsF$libSize),ylim=range(cellStatsF$geneDetect),
     pch=21,col=alpha("black",0.2),bg=alpha("black",0.1),cex=1.2,
     xlab="Transcripts detected per cell",ylab="Genes detected per cell")
points(geneDetect~libSize,data=cellStatsF[outToInspect,],
       pch=24,col=alpha("blue",0.2),bg=alpha("blue",0.1),cex=1.2)
points(geneDetect~libSize,data=cellStatsF[outToRemove,],
       pch=4,cex=1.2,col="red")
mtext(paste(dataName,"cell stats"),side=3,adj=0.02,line=-1.5,font=2,cex=1)
legend("bottomright",bty="n",pch=c(24,4,NA,NA),
       col=c("blue","red",NA,NA),pt.bg=alpha(c("blue",NA,NA,NA),0.3),
       legend=c(paste("Outliers to inspect:",sum(outToInspect)),
                paste("Outliers to remove:",sum(outToRemove)),
                paste(nrow(ebRawF)-nrow(ebRawF2),"genes removed"),
                paste(nrow(ebRawF2),"genes remain")))
par(mar=c(0,3,1,0))
hist(cellStatsF$libSize[!outToInspect | !outToRemove],
     freq=T,breaks=50,col="grey80",main=NULL,xlab=NA,ylab=NA,xaxt="n",yaxt="n")
if (any(outToInspect)) {
  hist(cellStatsF$libSize[outToInspect],add=T,
       freq=T,breaks=50,col=alpha("blue",.5),main=NULL,xlab=NA,ylab=NA,xaxt="n",yaxt="n")
}
if (any(outToRemove)) {
  hist(cellStatsF$libSize[outToRemove],add=T,
       freq=T,breaks=50,col=alpha("red",.5),main=NULL,xlab=NA,ylab=NA,xaxt="n",yaxt="n")
}
par(mar=c(3,0,0,1))
plotHistHoriz(cellStatsF$geneDetect[!outToInspect | !outToRemove])
if (any(outToInspect)) {
  plotHistHoriz(cellStatsF$geneDetect[outToInspect],col=alpha("blue",.5),add=T)
}
if (any(outToRemove)) {
  plotHistHoriz(cellStatsF$geneDetect[outToRemove],col=alpha("red",.5),add=T)
}

par(mar=c(3,3,0,0),mgp=2:0)
plot(geneDetect~libSize,data=cellStatsF[!outToInspect,],log="xy",
     xlim=range(cellStatsF$libSize),ylim=range(cellStatsF$geneDetect),
     pch=21,col=alpha("black",0.2),bg=alpha("black",0.1),cex=1.2,
     xlab="Transcripts detected per cell (log scale)",
     ylab="Genes detected per cell (log scale)")
points(geneDetect~libSize,data=cellStatsF[outToInspect,],
       pch=24,col=alpha("blue",0.2),bg=alpha("blue",0.1),cex=1.2)
points(geneDetect~libSize,data=cellStatsF[outToRemove,],
       pch=4,cex=1.2,col="red")
mtext(paste(dataName,"cell stats"),side=3,adj=0.02,line=-1.5,font=2,cex=1)
legend("topleft",bty="n",inset=c(0,.05),pch=c(24,4,NA,NA),
       col=c("blue","red",NA,NA),pt.bg=alpha(c("blue",NA,NA,NA),0.3),
       legend=c(paste("Outliers to inspect:",sum(outToInspect)),
                paste("Outliers to remove:",sum(outToRemove)),
                paste(nrow(ebRawF)-nrow(ebRawF2),"genes removed"),
                paste(nrow(ebRawF2),"genes remain")))
par(mar=c(0,3,1,0))
hist(log10(cellStatsF$libSize[!outToInspect | !outToRemove]),
     freq=T,breaks=50,col="grey80",main=NULL,xlab=NA,ylab=NA,xaxt="n",yaxt="n")
if (any(outToInspect)) {
  hist(log10(cellStatsF$libSize[outToInspect]),add=T,
       freq=T,breaks=50,col=alpha("blue",.5),main=NULL,xlab=NA,ylab=NA,xaxt="n",yaxt="n")
}
if (any(outToRemove)) {
  hist(log10(cellStatsF$libSize[outToRemove]),add=T,
       freq=T,breaks=50,col=alpha("red",.5),main=NULL,xlab=NA,ylab=NA,xaxt="n",yaxt="n")
}
par(mar=c(3,0,0,1))
plotHistHoriz(log10(cellStatsF$geneDetect[!outToInspect | !outToRemove]))
if (any(outToInspect)) {
  plotHistHoriz(log10(cellStatsF$geneDetect[outToInspect]),col=alpha("blue",.5),add=T)
}
if (any(outToRemove)) {
  plotHistHoriz(log10(cellStatsF$geneDetect[outToRemove]),col=alpha("red",.5),add=T)
}
```
While filtering out abnormally large libraries won't capture all doublets, these libraries are likely the result of capturing multiple cells in a droplet.  Removing these cells did not significantly affect the complexity of the dataName (minimal genes unique to these cells).


## Outlier inspection 

```{r what_are_those_cells, echo=FALSE,fig.height=4.2,fig.width=8.4}
if (any(outToInspect)) {
  ### Parameters you could edit ###
  topNum <- 3 # Number of highly expressed genes in outlier population to highlight
  removeOutlierPopulation <- T # Do you want to remove this outlier population from the analysis?
  
  ### Calculations ###
  gsOut <- data.frame(DR=apply(ebRawF2[,outToInspect[!outToRemove]],1,function(X) sum(X > 0)/length(X)),
                      MDTC=apply(ebRawF2[,outToInspect[!outToRemove]],1,function(X) mean(X[X>0])),
                      MTC=Matrix::rowMeans(ebRawF2[,outToInspect[!outToRemove]]))
  rownames(gsOut) <- rownames(ebRawF2)
  gsIn <- data.frame(DR=apply(ebRawF2[,!outToInspect[!outToRemove]],1,function(X) sum(X > 0)/length(X)),
                     MDTC=apply(ebRawF2[,!outToInspect[!outToRemove]],1,function(X) mean(X[X>0])),
                     MTC=Matrix::rowMeans(ebRawF2[,!outToInspect[!outToRemove]]))
  rownames(gsIn) <- rownames(ebRawF2)
  if (removeOutlierPopulation) {
    ebRawF3 <- ebRawF2[,!outToInspect[!outToRemove]]
    ebRawF3 <- ebRawF3[Matrix::rowSums(ebRawF3) > 0,]
  } else { ebRawF3 <- ebRawF2 }
  topHits <- 1:nrow(gsOut) %in% head(order(gsOut$MTC,decreasing=T),topNum)
  
  ### Plotting ###
  par(mfrow=c(1,2),mar=c(3,3,2,1),mgp=2:0)
  plot(log10(MDTC)~DR,data=gsOut,
       pch=21,cex=1.2,xlab="Proportion of cells detecting gene",
       ylab=expression(Log[10]~"Mean non-zero gene count"),
       col=alpha(c("black","red"),0.3)[topHits+1],
       bg=alpha(c("black","red"),0.1)[topHits+1],
       main=paste(dataName,"outlier cells"))
  text(log10(MDTC)~DR,data=gsOut[topHits,],
       labels=rownames(gsOut)[topHits],pos=2,col="red",cex=1.2)
  if (removeOutlierPopulation) {
    legend("topleft",inset=c(-.06,-.02),bty="n",cex=0.9,
           legend=c(paste(ncol(ebRawF2)-ncol(ebRawF3),"cells removed"),
                paste(ncol(ebRawF3),"cells remain"),
                paste(nrow(ebRawF2)-nrow(ebRawF3),"genes removed"),
                paste(nrow(ebRawF3),"genes remain")))
  } else {
    legend("topleft",inset=c(-.06,-.02),bty="n",cex=0.9,
           legend=c(paste(sum(outToInspect[!outToRemove]),"outlier cells"),
                paste(sum(!outToInspect[!outToRemove]),"cells in main population"),
                paste(nrow(ebRawF3)-sum(Matrix::rowSums(ebRawF3[,!outToInspect[!outToRemove]]) > 0),
                      "genes unique to outliers"),
                paste(sum(Matrix::rowSums(ebRawF2[,!outToInspect[!outToRemove]]) > 0),
                      "genes in main population")))
  }

  plot(log10(MDTC)~DR,data=gsIn,
       pch=21,cex=1.2,xlab="Proportion of cells detecting gene",
       ylab=expression(Log[10]~"Mean non-zero gene count"),
       col=alpha(c("black","red"),0.3)[topHits+1],
       bg=alpha(c("black","red"),0.1)[topHits+1],
       main=paste(dataName,"main cell population"))
  text(log10(MDTC)~DR,data=gsIn[topHits,],
       labels=rownames(gsIn)[topHits],pos=2,col="red",cex=1.2)
} else { ebRawF3 <- ebRawF2 }
```


```{r cleanup1, include=F}
rm(list=ls()[!ls() %in% c("ebRawF3","dataName","dataPath","plotHistHoriz","rainbow2",
                          "egDB","dataSpecies","cycloneSpeciesMarkers","geneLengthPath")])
gc()
```

```{r SCEset, include=F}
if (!file.exists(paste0(dataPath,"ebRawS.RData"))) {
  ebRawS <- SingleCellExperiment(list(counts=ebRawF3))
  ebRawS <- scater::calculateQCMetrics(ebRawS)
  save(ebRawS,file=paste0(dataPath,"ebRawS.RData"))
} else {
  load(paste0(dataPath,"ebRawS.RData"))
}
rm(ebRawF3)
gc()
```

Data processing will now be performed based on a workflow published by the Marioni group (Lun et al., F1000Research 2016; http://dx.doi.org/10.12688/f1000research.9501.2).  


## Filter out low abundance genes

Noisy genes must be removed to prevent them from skewing normalization.  The filtering method in *Seurat* removes only genes detected in very few cells, which is sufficient for normalization while removing as few genes as possible. 

```{r geneFilt, echo=F,fig.height=6.3,fig.width=6.3,fig.show="hold"}
geneStats <- data.frame(DR=apply(counts(ebRawS),1,function(X) sum(X > 0)/length(X)),
                        MDTC=apply(counts(ebRawS),1,function(X) mean(X[X > 0])),
                        cellMax=apply(counts(ebRawS),1,max))
drop_g <- geneStats$DR < 3/ncol(ebRawS)
ebRawSF <- ebRawS[!drop_g,]

layout(matrix(c(2,1,0,3),2),widths=c(6,1),heights=c(1,6))
par(mar=c(3,3,0,0),mgp=2:0)
temp_H <- cut(log10(geneStats[order(geneStats$cellMax,decreasing=F),"cellMax"]),breaks=100,labels=F)
plot(log10(MDTC)~log10(DR),data=geneStats[order(geneStats$cellMax,decreasing=F),],
     pch=21,col=viridis(100,0.5,1,0)[temp_H],bg=viridis(100,0.3,1,0)[temp_H],
     xlab=expression(Log[10]~"Proportion of cells detecting gene"),
     ylab=expression(Log[10]~"Mean transcript count of detected genes (MDTC)"))
points(log10(MDTC)~log10(DR),data=geneStats[drop_g,],
       pch=4,col=alpha("red",0.5),cex=1.2)
legend("top",bty="n",pch=c(4,NA,NA),col=c("red",NA,NA),cex=1.1,inset=c(0,.06),
       legend=c("Gene in < 3 cells",
                paste("Genes removed:",sum(drop_g)),
                paste("Genes remaining:",nrow(ebRawSF))))
segments(x0=seq(quantile(range(log10(geneStats$DR)),.2),
                quantile(range(log10(geneStats$DR)),.8),length.out=1000),
         y0=rep(max(log10(geneStats$MDTC)) * 1.02),
         y1=rep(max(log10(geneStats$MDTC))),col=viridis(1000))
text(x=c(quantile(range(log10(geneStats$DR)),.2),
         median(range(log10(geneStats$DR))),
         quantile(range(log10(geneStats$DR)),.8)),
     y=rep(max(log10(geneStats$MDTC)) * .98,3),
     labels=c(min(geneStats$cellMax),
              expression(Log[10]~bold(max)~transcript~count),
              max(geneStats$cellMax)),cex=1.1)

par(mar=c(0,3,0,0))
hist(log10(geneStats$DR),freq=T,breaks=100,col="grey80",main=NULL,xaxt="n")
title("Gene expression distribution",line=-2,cex.main=1.5)
par(mar=c(3,0,0,0))
barplot(hist(log10(geneStats$MDTC),breaks=100,plot=F)$counts,
        horiz=T,space=0,col="grey80",main=NULL,xlab="Frequency")
```

```{r cleanup2, include=F}
rm(list=ls()[!ls() %in% c("ebRawSF","dataName","dataPath","plotHistHoriz","rainbow2")])
gc()
```

# Normalization  

Next step is normalization.  Marioni proposed a normalization technique that attempts to generate cell-specific size factors that are robust to differential expression between genes in a heterogenous sample, unlike simple library-size normalization (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7).  This method correlates strongly with library size normalization for homogenous samples, but solves a series of linear equations to deconvolute cell-specific size factors for normalization.  In order to better handle heterogenous data, they suggest separating the data by simple heirarchical clustering of a Spearman correlation-based distance metric so that they can normalize the separate subpopulations separately to prevent the suppression of true differential expression during normalization.  

Normalization is carried out by assigning size factors per gene by the pooling and deconvolution method, then taking the log-ratio between each count and its size factor, and adding a pseudocount of one.  Log-transforming the data stabilizes variance by reducing the impact of a few highly variable genes.  

Following this, it is suggested to investigate sources of technical variance, but without spike-ins or any annotated possible sources of variation, this step is impossible with this data.  

```{r normalize_by_deconvolution_quickCluster, include=F}
if (!file.exists(paste0(dataPath,"ebNorm.RData"))) {
  qClust <- quickCluster(ebRawSF,min.size=200) #default
  names(qClust) <- colnames(ebRawSF)
  ebRawSF <- computeSumFactors(ebRawSF,clusters=qClust)
  ebN <- ebRawSF[,!sizeFactors(ebRawSF) <= 0]
  ebN <- normalize(ebN)
  naCells <- apply(exprs(ebN),2,function(X) any(is.na(X)))
  if (any(naCells)) {
    exprs(ebN)[,naCells] <- min(apply(exprs(ebN),1,function(X) min(X,na.rm = T)))
  }
  save(qClust,ebN,file=paste0(dataPath,"ebNorm.RData"))
} else {
  load(paste0(dataPath,"ebNorm.RData"))
}

geneStatsN <- data.frame(DR=apply(exprs(ebN),1,function(X) sum(X > 0))/ncol(ebN),
                         MDTC=apply(exprs(ebN),1,function(X) mean(X[X > 0])),
                         MTC=Matrix::rowMeans(exprs(ebN)),sumTC=Matrix::rowSums(exprs(ebN)),
                         cellMax=apply(exprs(ebN),1,max))

clustCols <- rainbow2(length(levels(qClust)))
temp_randcells <- sample.int(ncol(ebN))
```

```{r normalize_fig1, echo=F,fig.height=4.2,fig.width=8.4,fig.show="hold"}
temp_times <- as.factor(sub("_.+$","",colnames(ebRawSF)))
layout(matrix(c(2,1,0,3,5,4,0,6),2),
       widths=c(3.5,.7,3.5,.7),heights=c(.7,3.5))

## GeneDetect~LibSize by QuickCluster
par(mar=c(3,3,0,0),mgp=2:0)
plot(x=log10(colData(ebRawSF)$total_counts)[temp_randcells],
     y=log10(colData(ebRawSF)$total_features)[temp_randcells],
     pch=21,col=alpha(clustCols,0.4)[qClust][temp_randcells],
     bg=alpha(clustCols,0.2)[qClust][temp_randcells],
     xlab=expression(log[10]~"Library Size"),ylab=expression(log[10]~"Genes Detected"))
points(log10(colData(ebRawSF)$total_counts)[!colnames(ebRawSF) %in% colnames(ebN)],
       log10(colData(ebRawSF)$total_features)[!colnames(ebRawSF) %in% colnames(ebN)],
       pch=4,col="red")
mtext("Clusters for normalization",side=3,line=-1.5,font=2)
legend("topleft",bty="n",ncol=2,inset=c(0,.05),lwd=2,pch=21,
       col=alpha(clustCols[seq_along(levels(qClust))],0.3),
       pt.bg=alpha(clustCols[seq_along(levels(qClust))],0.1),
       legend=paste0(levels(qClust),": ",table(qClust)))
legend("bottomright",bty="n",pch=4,col="red",
       legend=paste(ncol(ebRawSF) - ncol(ebN),"cells could not be normalized"))

par(mar=c(0,3,.1,0))
temp_density <- tapply(log10(colData(ebRawSF)$total_counts),qClust,function(X) density(X))
plot(x=NULL,y=NULL,xlim=range(log10(colData(ebRawSF)$total_counts)),
     ylim=range(unlist(lapply(temp_density,function(X) range(X$y)))),
     xlab=NULL,ylab="Frequency",xaxt="n")
for (x in seq_along(levels(qClust))) {
  lines(temp_density[[x]],lwd=2,col=alpha(clustCols,0.7)[x])
}

par(mar=c(3,0,0,.1))
temp_density <- tapply(log10(colData(ebRawSF)$total_features),qClust,function(X) density(X))
plot(x=NULL,y=NULL,ylim=range(log10(colData(ebRawSF)$total_features)),
     xlim=range(unlist(lapply(temp_density,function(X) range(X$y)))),
     ylab=NULL,xlab="Frequency",yaxt="n")
for(x in seq_along(levels(qClust))) {
  lines(x=temp_density[[x]]$y,y=temp_density[[x]]$x,
        lwd=2,col=alpha(clustCols,0.7)[x])
}

## SizeFactor~LibSize by QuickCluster
qClustF <- qClust[colnames(ebN)]
par(mar=c(3,3,0,0),mgp=2:0)
plot(x=log10(colData(ebN)$total_counts)[temp_randcells],
     y=log10(sizeFactors(ebN))[temp_randcells],
     pch=21,col=alpha(clustCols,0.4)[qClustF][temp_randcells],
     bg=alpha(clustCols,0.2)[qClustF][temp_randcells],
     xlab=expression(log[10]~"Library Size"),ylab=expression(log[10]~"Size Factor"))
mtext("Clusters for normalization",side=3,line=-1.5,font=2)
legend("bottomright",bty="n",ncol=2,inset=c(0,.03),lwd=2,pch=21,
       col=alpha(clustCols[seq_along(levels(qClustF))],0.3),
       pt.bg=alpha(clustCols[seq_along(levels(qClustF))],0.1),
       legend=paste0(levels(qClustF),": ",table(qClustF)))
mtext(paste(ncol(ebRawSF) - ncol(ebN),"cells were not normalized"),
      side=1,line=-1.1,adj=.99,cex=.8)

par(mar=c(0,3,.1,0))
temp_density <- tapply(log10(colData(ebN)$total_counts),qClustF,function(X) density(X))
plot(x=NULL,y=NULL,xlim=range(log10(colData(ebN)$total_counts)),
     ylim=range(unlist(lapply(temp_density,function(X) range(X$y)))),
     xlab=NULL,ylab="Frequency",xaxt="n")
for (x in seq_along(levels(qClustF))) {
  lines(temp_density[[x]],lwd=2,col=alpha(clustCols,0.7)[x])
}

par(mar=c(3,0,0,.1))
temp_density <- tapply(log10(sizeFactors(ebN)),qClustF,function(X) density(X))
plot(x=NULL,y=NULL,ylim=range(log10(sizeFactors(ebN))),
     xlim=range(unlist(lapply(temp_density,function(X) range(X$y)))),
     ylab=NULL,xlab="Frequency",yaxt="n")
for(x in seq_along(levels(qClustF))) {
  lines(x=temp_density[[x]]$y,y=temp_density[[x]]$x,
        lwd=2,col=alpha(clustCols,0.7)[x])
}

```

Cells that fail to normalize are generally due to poor information content (small library size, weak gene expression relative to other cells).

```{r cleanup3, include=F}
rm(list=ls()[!ls() %in% c("ebN","dataPath")])
gc()
```

# Highly variable genes  
Identification of highly variable genes is done by assuming most endogenous genes are not variably expressed, and fitting a curve to these genes when comparing variance to mean. This curve is presumed to represent technical variation, and thus highly variable genes are those with variance significantly greater than this curve. The method used here from *scran* isn’t that different in logic to the *Seurat* method, but fitting a spline is just a little more refined way of going about it than Seurat’s binning method.

```{r HVG2, echo=F,fig.height=6.3,fig.width=8.4}
var.fit <- trendVar(exprs(ebN),method="loess",parametric=T)
var.out <- decomposeVar(exprs(ebN),var.fit)
bioCut <- 0
bioCutFDR <- 1e-2
hvg <- var.out[which(var.out$FDR <= bioCutFDR & var.out$bio >= bioCut),]
hvg <- hvg[order(hvg$bio,decreasing=T),]

par(mar=c(3,3,3,1),mgp=2:0)
plot(total~mean, data=var.out[!rownames(var.out) %in% rownames(hvg),],
     ylim=range(var.out$total),xlim=range(var.out$mean),
     pch=21,col=alpha("black",0.3),bg=alpha("black",0.1),
     xlab="Mean log-expression",ylab="Variance of log-expression")
points(total~mean, data=var.out[rownames(var.out) %in% rownames(hvg),],
       pch=21,col=alpha("red",0.3),bg=alpha("red",0.1))
lines(var.out$mean[order(var.out$mean)],var.out$tech[order(var.out$mean)],
      col=alpha("red",0.5),lwd=2)
text(total~mean,data=var.out[rownames(hvg[1:10,]),],
     labels=rownames(hvg[1:10,]),pos=4,col=alpha("red",0.5))
legend("top",bty="n",inset=c(0,-.12),ncol=2,xpd=NA,
       lwd=c(2,NA,NA),pch=c(NA,21,NA),col=alpha(c("red","red",NA),0.5),pt.bg=alpha(c(NA,"red",NA),0.3),
       legend=c("Predicted technical variance",
                paste("Biological variance > 0 at FDR <=",bioCutFDR),
                paste(nrow(hvg),"/",nrow(ebN),"highly variable genes")))
```

```{r output_for_clustering, include=F}
ebNorm <- exprs(ebN)
pDat <- colData(ebN)[,c("total_features","total_counts")]
save(ebNorm,pDat,hvg,file=paste0(dataPath,"clustInputs.RData"))

write.csv(exprs(ebN),file=paste0(dataPath,"ebNorm.csv"),quote=F)
```

